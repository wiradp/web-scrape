# ğŸ’» Laptop Market Analytics â€” Automated Data Pipeline

---

## ğŸŒ What is this?
We're working on an automated system designed to track laptop prices across Indonesia. It pulls data from online marketplaces, cleans it up, and presents it on a public dashboard for everyone to see.

This system is more advanced than simple scrapers because it remembers history. When a laptop's price changes today, it saves the old price instead of deleting it. This feature enables users to see price trends and quickly identify new product arrivals.

---

## ğŸš€ Key Features (What's Done)
**1. Smart Data Collection**
- **Automated Scraping:** Collects thousands of laptop data points automatically.
- **Data Cleaning:** Converts messy text (e.g., "16gb ddr4") into clean data columns (RAM: 16 GB).

**2. Historical Tracking (SCD Type 2)**
- **Price History:** If a price changes, the old data is archived, not deleted.
- **Change Logging:** The system records exactly when a price changed or when a new product was added.

**3. Hybrid Database System**
- **Local Processing:** Uses **SQLite** for fast, safe data processing on the local machine.
- **Cloud Sync:** Automatically syncs clean data to **Supabase (PostgreSQL)** so the public dashboard is always up-to-date.

**4. Interactive Dashboard**
- **"What's New" Tab:** A special feature that shows New Arrivals and Price Drops/Hikes from the latest update.
- **Filters:** Filter by Brand, RAM, Processor, and GPU.
- **Analytics:** Visualizes price distributions and spec trends.

---

## ğŸ—ï¸ Architecture: How it Works
The system runs on a pipeline called `run_pipeline.sh` which executes these steps in order:

1. `scraper.py` Visits the website and downloads raw data into a local database.
2. `etl.py` **(Extract, Transform, Load)** * Cleans the raw data.
  - Extracts specs (Brand, CPU, GPU).
  - Compares new data vs. old data to detect price changes.
5. `seeder.py` Uploads the processed data from the Local Database to the **Supabase Cloud**.
6. `dashboard.py` The user interface (built with Streamlit) fetches data from Supabase and displays it to the user.

---

## ğŸ› ï¸ Tech Stack
- **Language**: Python ğŸ
- **Automation**: Bash Script & Cron Job
- **Data Processing**: Pandas, NumPy
- **Database**: SQLite (Local) & Supabase (Cloud/PostgreSQL)
- **Visualization**: Streamlit, Plotly, Matplotlib

---

## ğŸ”® Future Roadmap
- ğŸ§  **AI Semantic Search:** "Find me a cheap laptop for video editing" (Using Vector Embeddings).
- ğŸ“† **Price Forecasting:** Predict when prices might drop using Machine Learning.
- ğŸ”” **Email Alerts:** Notify users when their favorite laptop gets a discount.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ data/               # Local database storage
â”œâ”€â”€ logs/               # Automation logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py      # Grabs data from web
â”‚   â”œâ”€â”€ etl.py          # Cleans & processes history
â”‚   â”œâ”€â”€ seeder.py       # Syncs local DB to Cloud
â”‚   â”œâ”€â”€ dashboard.py    # The Streamlit App
â”‚   â””â”€â”€ ...
â”œâ”€â”€ run_pipeline.sh     # Main automation script
â””â”€â”€ requirements.txt    # Python dependencies
```

---

**Author**: [Wira Dhana Putra](https://wiradp.github.io)

**Status**: Live Production ğŸš€

**Live Demo**: [Click Here to View Dashboard](https://web-scrape-dashboard.streamlit.app/)

_Created with â¤ï¸ by Wira_
