{
  "nb_path": "/mnt/data/web-scrape2.ipynb",
  "n_cells": 18,
  "n_code_cells": 18,
  "n_markdown_cells": 0,
  "first_5_code_cells": [
    "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport re\nimport time\n\ndef fetch_page(url, headers):\n    \"\"\"Mengirim permintaan GET ke URL dan mengembalikan objek BeautifulSoup.\"\"\"\n    try:\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        return BeautifulSoup(response.text, 'html.parser')\n    except requests.RequestException as e:\n        print(f\"Error saat mengambil URL {url}: {e}\")\n        return None\n\ndef clean_text(text):\n    \"\"\"\n    Membersihkan teks dari whitespace characters (\\r, \\n, \\t) dan multiple spaces.\n    \"\"\"\n    if not text:\n        return text\n    \n    # Replace \\r, \\n, \\t dengan space\n    cleaned = re.sub(r'[\\r\\n\\t]+', ' ', text)\n    # Replace multiple spaces dengan single space\n    cleaned = re.sub(r'\\s+', ' ', cleaned)\n    # Trim leading and trailing spaces\n    return cleaned.strip()\n\n# --- FUNGSI PARSING YANG DIPERBAIKI ---\ndef parse_products_from_table(soup):\n    \"\"\"\n    Mengekstrak informasi produk dari elemen <table> dengan pembersihan teks.\n    \"\"\"\n    products = []\n    # Menargetkan tabel utama di halaman\n    table = soup.find('table')\n    if not table:\n        print(\"Elemen <table> tidak ditemukan.\")\n        return []\n\n    # Mengambil semua baris (tr) di dalam tabel\n    rows = table.find_all('tr')\n    \n    # Loop melalui setiap baris, lewati baris header jika perlu\n    for row in rows[1:]: # Mulai dari indeks 1 untuk melewati header\n        try:\n            cols = row.find_all('td')\n            # Memastikan baris memiliki setidaknya 2 kolom (nama dan harga)\n            if len(cols) >= 2:\n                # Kolom pertama (indeks 0) adalah nama produk - DIBERSIHKAN\n                raw_name = cols[0].get_text()\n                name = clean_text(raw_name)\n                \n                # Kolom kedua (indeks 1) adalah harga - DIBERSIHKAN\n                raw_price = cols[1].get_text()\n                price_str = clean_text(raw_price)\n                \n                # Membersihkan harga dari 'Rp', '.', dan spasi\n                price_cleaned = int(re.sub(r'[^\\d]', '', price_str))\n                \n                # Hanya tambahkan jika nama dan harga valid\n                if name and price_cleaned > 0:\n                    products.append({\n                        'Product_Name': name,\n                        'Price': price_cleaned\n                    })\n        except (ValueError, IndexError) as e:\n            # Lewati baris yang mungkin kosong atau formatnya salah\n            continue\n        except Exception as e:\n            print(f\"Error memproses baris: {e}\")\n            continue\n            \n    return products\n\n# --- Alur Kerja Utama (Main Workflow) ---\n\nif __name__ == \"__main__\":\n    URL = \"https://viraindo.com/notebook.html\"\n    HEADERS = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n    }\n    \n    print(\"Mengambil data dari halaman...\")\n    soup = fetch_page(URL, HEADERS)\n    \n    all_products = []\n    if soup:\n        all_products = parse_products_from_table(soup)\n\n    if not all_products:\n        print(\"Tidak ada produk yang ditemukan. Proses berhenti.\")\n    else:\n        # Konversi ke DataFrame\n        df = pd.DataFrame(all_products)\n        \n        # Simpan ke CSV\n        df.to_csv('data/notebooks_viraindo.csv', index=False)\n        \n        print(f\"\\nProses scraping selesai. Total {len(df)} produk ditemukan.\")\n        print(\"Data berhasil disimpan ke 'notebooks_viraindo.csv'\")\n        print(\"\\nContoh 5 data teratas:\")\n        print(df.head())",
    "# Set pandas display options untuk menampilkan seluruh konten\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', None)\n\n# Membaca file CSV untuk verifikasi\ndf = pd.read_csv('notebooks_viraindo.csv')\ndf.head()",
    "# Mengcopy dataframe ke df baru bernama df_copy\ndf_copy = df.copy()",
    "# Menampilkan nilai kosong pada DataFrame\ndf.isnull().sum()",
    "# Menampilkan informasi DataFrame\ndf.info()"
  ],
  "first_5_md_cells": []
}